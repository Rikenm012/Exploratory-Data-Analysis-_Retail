{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv(r'D:\\internship\\SampleSuperstore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of the dataset\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "\n",
    "# checking the first five rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the data types of the columns\n",
    "print(\"Data types of columns:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the missing values in the dataset\n",
    "print(\"\\nMissing values in the dataset:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the duplicat values in the dataset\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will give us the count of duplicate rows in the dataset. In this case, there are 17 duplicate rows and we will remove.\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ship Mode'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Category', y='Profit', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will check for any outliers in the numerical columns of the dataset.\n",
    "num_cols = ['Sales', 'Quantity', 'Discount', 'Profit']\n",
    "\n",
    "for col in num_cols:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5*iqr\n",
    "    upper_bound = q3 + 1.5*iqr\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    print(col, outliers.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Sales by Category and Sub-Category\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='Category', y='Sales', hue='Sub-Category', data=df)\n",
    "plt.title('Sales by Category and Sub-Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for all numerical columns\n",
    "df.hist(bins=20, figsize=(20,10))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(x=\"Category\", data=df)\n",
    "plt.show()\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(x=\"Sub-Category\", data=df,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of numerical columns\n",
    "num_cols = ['Sales', 'Quantity', 'Discount', 'Profit']\n",
    "fig, ax = plt.subplots(nrows=len(num_cols), figsize=(5,10))\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    ax[i].boxplot(df[col])\n",
    "    ax[i].set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "sns.scatterplot(x=\"Sales\", y=\"Profit\", data=df)\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_counts = df['Segment'].value_counts()\n",
    "plt.pie(segment_counts, labels=segment_counts.index, autopct='%1.1f%%',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot\n",
    "sns.pairplot(df, vars=['Sales', 'Profit', 'Quantity', 'Discount'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "sns.histplot(data=df, x='Sales', kde=True)\n",
    "plt.title('Distribution of Sales')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "sns.boxplot(data=df, x='Sales')\n",
    "plt.title('Box plot of Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(df['Sales'], model='additive', period=12)\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top profitable products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_products = df.groupby(\"Sub-Category\").sum().sort_values(\"Profit\", ascending=False)\n",
    "print(top_products.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top profitable cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities = df.groupby(\"City\").sum().sort_values(\"Profit\", ascending=False)\n",
    "print(top_cities.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top profitable states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_states = df.groupby(\"State\").sum().sort_values(\"Profit\", ascending=False)\n",
    "print(top_states.head(10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top profitable segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_segments = df.groupby(\"Segment\").sum().sort_values(\"Profit\", ascending=False)\n",
    "print(top_segments.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top profitable regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_regions = df.groupby(\"Region\").sum().sort_values(\"Profit\", ascending=False)\n",
    "print(top_regions.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top profitable categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_categories = df.groupby(\"Category\").sum().sort_values(\"Profit\", ascending=False)\n",
    "print(top_categories.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top loss-making products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_products = df.groupby(\"Sub-Category\").sum().sort_values(\"Profit\", ascending=True)\n",
    "print(loss_products.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top loss-making cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_cities = df.groupby(\"City\").sum().sort_values(\"Profit\", ascending=True)\n",
    "print(loss_cities.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top loss-making states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_states = df.groupby(\"State\").sum().sort_values(\"Profit\", ascending=True)\n",
    "print(loss_states.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top loss-making segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_segments = df.groupby(\"Segment\").sum().sort_values(\"Profit\", ascending=True)\n",
    "print(loss_segments.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top loss-making regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_regions = df.groupby(\"Region\").sum().sort_values(\"Profit\", ascending=True)\n",
    "print(loss_regions.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top loss-making categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_categories = df.groupby(\"Category\").sum().sort_values(\"Profit\", ascending=True)\n",
    "print(loss_categories.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "Based on the exploratory data analysis, we can identify several weak areas where we can work to make more profit. These areas include:\n",
    "\n",
    "#### Improving the sales and profit of the office supplies category\n",
    "#### Addressing the negative profit margins in the central and eastern regions\n",
    "#### Reducing the losses in the furniture and technology categories\n",
    "#### Addressing the negative profit margins in certain states and cities\n",
    "#### Analyzing the customer segments and identifying areas for improvement in sales and profit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
